{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that generates samples approximate RGO. The target is defined in Potential class.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import targets\n",
    "import cProfile\n",
    "import pstats\n",
    "import random\n",
    "import argparse\n",
    "import os\n",
    "from utils import target_func, mixing_time, TV_estimation, target_funnel\n",
    "import matplotlib.ticker as ticker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function as the original approximate RGO\n",
    "def generate_samples(step_size, x_y, f):\n",
    "    dimension = f.dimension\n",
    "    ite = 0\n",
    "    while True:\n",
    "        samples = np.random.multivariate_normal(mean = x_y, cov = step_size * np.identity(dimension), size = 2)\n",
    "        # Compute the acceptance probability\n",
    "        gradient = f.firstOrder(x_y)\n",
    "        a = f.zeroOrder(samples[0,:])-np.dot(gradient,samples[0,:])\n",
    "        b = f.zeroOrder(samples[1,:])-np.dot(gradient,samples[1,:])\n",
    "        # The code works even when rho is inf. One can also take the log transformation\n",
    "        rho = np.exp(b-a)\n",
    "        u = np.random.uniform(0,1)\n",
    "        ite = ite + 1\n",
    "        if u < rho/2:\n",
    "            break\n",
    "    return samples[0,:],ite\n",
    "\n",
    "# Define a function that estimates the local step size\n",
    "def estimate_step_size(step_size, tolerance, y, f, size = 100, reduce = 0.5):\n",
    "    dimension = f.dimension\n",
    "    # Compute the desired subexponential parameter\n",
    "    x_y = f.solve1(y, step_size)\n",
    "    testFunction = lambda C : np.mean(np.exp(np.abs(Y)**(2/(1+f.alpha))/C))-2\n",
    "    while True:\n",
    "        # Generate random samples from a Gaussian distribution: \\exp^{-(x-x_y)^2/(2\\step_size)}\n",
    "        samples = np.random.multivariate_normal(mean = x_y, cov = step_size * np.identity(dimension), size = size*2)\n",
    "        Y = np.zeros(size)\n",
    "        for i in range(size):\n",
    "            gradient = f.firstOrder(x_y)\n",
    "            a = f.zeroOrder(samples[i])-np.dot(gradient,samples[i])\n",
    "            b = f.zeroOrder(samples[i+size])-np.dot(gradient,samples[i+size])\n",
    "            Y[i] = b-a\n",
    "        # Estimate the subexponential parameter of Y: find the smallest C>0 such that E[\\exp^{\\abs(Y)/C}] \\leq 2 by binary search for smooth potentials\n",
    "        # Initialize the interval\n",
    "        left = 0\n",
    "        right = dimension**(f.alpha/(f.alpha+1)) # The estimated upper bound of the subexponential parameter\n",
    "        while testFunction(right)>0:\n",
    "            left = right\n",
    "            right = 2*right\n",
    "        # Initialize the middle point\n",
    "        mid = (left+right)/2\n",
    "        # Initialize the value of the function\n",
    "        f_mid = testFunction(mid)\n",
    "        while abs(f_mid) > 1e-1:\n",
    "            if f_mid > 0:\n",
    "                left = mid\n",
    "            else:\n",
    "                right = mid\n",
    "            mid = (left+right)/2\n",
    "            f_mid =  testFunction(mid)\n",
    "        if mid < 1 / ( np.log(6/tolerance) / np.log(2)  * 0.5) : \n",
    "            break\n",
    "        else:\n",
    "            step_size = step_size * reduce\n",
    "            x_y = f.solve1(y, step_size) \n",
    "    return step_size, x_y\n",
    "\n",
    "# Define the outer loop of proximal sampler\n",
    "def proximal_sampler(initial_step_size, num_samples, num_iter, f, fixed, adjusted_size=10, tolerance=1e-2, reduce = 0.5):\n",
    "    dimension = f.dimension\n",
    "\n",
    "    samples = np.zeros([num_samples,num_iter,dimension])\n",
    "    Ysamples = np.zeros([num_samples,dimension])\n",
    "    rejections = np.zeros([num_samples, num_iter])\n",
    "    step_sizes = np.zeros([num_samples,num_iter])\n",
    "\n",
    "    # Initialize the samples for both fxied and adaptive versions\n",
    "    samples[:,0,:] = np.random.multivariate_normal(mean = 2 + np.zeros(dimension), cov = np.identity(dimension), size = num_samples)\n",
    "    for j in range(num_samples):\n",
    "        Ysamples[j,:] = np.random.multivariate_normal(mean =  np.zeros(dimension), cov = np.identity(dimension), size = 1)\n",
    "        if fixed == False:\n",
    "            step_size, x_y = estimate_step_size(initial_step_size, tolerance, Ysamples[j,:], f, size = 100, reduce = reduce)\n",
    "            step_sizes[j,0] = step_size\n",
    "    \n",
    "    if fixed == True:    \n",
    "        print(f'fixed sampling') \n",
    "        for i in range(1,num_iter):\n",
    "            for j in range(num_samples):\n",
    "                x_y = f.solve1(Ysamples[j,:], initial_step_size)\n",
    "                samples[j,i,:],ite = generate_samples(initial_step_size, x_y, f)\n",
    "                Ysamples[j,:] = np.random.multivariate_normal(mean = samples[j,i,:], cov = initial_step_size * np.identity(dimension), size = 1) \n",
    "                rejections[j,i] = ite\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Steps:{i}\")\n",
    "                if f.times2 > 0:\n",
    "                    print(f\"Averaged optimization steps of the new one: {f.ite2/f.times2}\")\n",
    "                print(f\"Averaged rejection steps : {np.mean(rejections[:,i])}\")\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    if fixed == False:\n",
    "        print(f'adpative sampling')\n",
    "        for i in range(1,num_iter):\n",
    "            for j in range(num_samples):\n",
    "                # if i < 100 or (i >= 100 and np.random.uniform(0,1) < 0.001):\n",
    "                if True:\n",
    "                    dynamic_size = 100 if i < 5 else adjusted_size\n",
    "                    step_size, x_y = estimate_step_size(1/reduce*step_sizes[j,i-1], tolerance, Ysamples[j,:], f, size = dynamic_size, reduce = reduce)\n",
    "                else:\n",
    "                    x_y = f.solve1(Ysamples[j,:], step_sizes[j,i-1])\n",
    "                    step_size = step_sizes[j,i-1]\n",
    "                samples[j,i,:],ite = generate_samples(step_size, x_y, f)\n",
    "                Ysamples[j,:] = np.random.multivariate_normal(mean = samples[j,i,:], cov = step_size * np.identity(dimension), size = 1)  \n",
    "                step_sizes[j,i] = step_size\n",
    "                rejections[j,i] = ite  \n",
    "            \n",
    "            # statistics for the first sample\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Steps:{i}\")\n",
    "                print(f\"Averaged_step_size:{np.mean(step_sizes[:,i])}\")\n",
    "                if f.times2 > 0:\n",
    "                    print(f\"Averaged optimization steps of the new one: {f.ite2/f.times2}\")\n",
    "                print(f\"Averaged rejection steps : {np.mean(rejections[:,i])}\")\n",
    "    return samples, step_sizes\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L=14.633606609426153\n",
      "min_step_size=1.2275845356826385e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2991756/3482300543.py:24: RuntimeWarning: overflow encountered in exp\n",
      "  testFunction = lambda C : np.mean(np.exp(np.abs(Y)**(2/(1+f.alpha))/C))-2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adpative sampling\n",
      "Steps:100\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:200\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 2.0\n",
      "Steps:300\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:400\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 2.0\n",
      "Steps:500\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 5.0\n",
      "Steps:600\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 2.0\n",
      "0.00041560975384879095\n",
      "Steps:700\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 2.0\n",
      "Steps:800\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:900\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 3.0\n",
      "Steps:1000\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:1100\n",
      "Averaged_step_size:0.01953125\n",
      "Averaged rejection steps : 2.0\n",
      "Steps:1200\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 6.0\n",
      "Steps:1300\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:1400\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 2.0\n",
      "3.213368766930478e-05\n",
      "adpative sampling\n",
      "0.0007457363159862257\n",
      "Steps:100\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:200\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 2.0\n",
      "0.0008692199086524782\n",
      "Steps:300\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:400\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 4.0\n",
      "Steps:500\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:600\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:700\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 3.0\n",
      "Steps:800\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 2.0\n",
      "Steps:900\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 2.0\n",
      "Steps:1000\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 3.0\n",
      "Steps:1100\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 4.0\n",
      "Steps:1200\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 6.0\n",
      "Steps:1300\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:1400\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 2.0\n",
      "adpative sampling\n",
      "Steps:100\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:200\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 2.0\n",
      "0.0022428505994498797\n",
      "Steps:300\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 3.0\n",
      "Steps:400\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:500\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:600\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:700\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 2.0\n",
      "Steps:800\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:900\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 2.0\n",
      "Steps:1000\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 5.0\n",
      "Steps:1100\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 5.0\n",
      "Steps:1200\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:1300\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 1.0\n",
      "0.00274588888239505\n",
      "0.001542933842397542\n",
      "Steps:1400\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 5.0\n",
      "0.0010924268099657946\n",
      "adpative sampling\n",
      "Steps:100\n",
      "Averaged_step_size:0.15625\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:200\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 3.0\n",
      "Steps:300\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 2.0\n",
      "Steps:400\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 4.0\n",
      "0.0012156890820588034\n",
      "Steps:500\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:600\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 1.0\n",
      "0.0020854310398205423\n",
      "Steps:700\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 4.0\n",
      "Steps:800\n",
      "Averaged_step_size:0.15625\n",
      "Averaged rejection steps : 1.0\n",
      "0.0006495481751742456\n",
      "Steps:900\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:1000\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 4.0\n",
      "0.0024516140409638824\n",
      "Steps:1100\n",
      "Averaged_step_size:0.15625\n",
      "Averaged rejection steps : 2.0\n",
      "0.0002030497358707176\n",
      "Steps:1200\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 2.0\n",
      "Steps:1300\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 2.0\n",
      "Steps:1400\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 1.0\n",
      "adpative sampling\n",
      "Steps:100\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 6.0\n",
      "Steps:200\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:300\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 2.0\n",
      "0.0008096046632078475\n",
      "Steps:400\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 5.0\n",
      "Steps:500\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 4.0\n",
      "Steps:600\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:700\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:800\n",
      "Averaged_step_size:0.01953125\n",
      "Averaged rejection steps : 2.0\n",
      "Steps:900\n",
      "Averaged_step_size:0.078125\n",
      "Averaged rejection steps : 3.0\n",
      "Steps:1000\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:1100\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 3.0\n",
      "Steps:1200\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:1300\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 5.0\n",
      "Steps:1400\n",
      "Averaged_step_size:0.0390625\n",
      "Averaged rejection steps : 5.0\n",
      "adpative sampling\n",
      "Steps:100\n",
      "Averaged_step_size:0.10000000000000009\n",
      "Averaged rejection steps : 1.0\n",
      "0.0013139101807801052\n",
      "Steps:200\n",
      "Averaged_step_size:0.010000000000000009\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:300\n",
      "Averaged_step_size:0.10000000000000009\n",
      "Averaged rejection steps : 4.0\n",
      "Steps:400\n",
      "Averaged_step_size:0.010000000000000009\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:500\n",
      "Averaged_step_size:0.010000000000000009\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:600\n",
      "Averaged_step_size:0.010000000000000009\n",
      "Averaged rejection steps : 2.0\n",
      "3.1594511339801274e-05\n",
      "0.0011463905843998711\n",
      "Steps:700\n",
      "Averaged_step_size:0.10000000000000009\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:800\n",
      "Averaged_step_size:0.10000000000000009\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:900\n",
      "Averaged_step_size:0.010000000000000009\n",
      "Averaged rejection steps : 1.0\n",
      "0.003643259544879181\n",
      "Steps:1000\n",
      "Averaged_step_size:0.010000000000000009\n",
      "Averaged rejection steps : 4.0\n",
      "Steps:1100\n",
      "Averaged_step_size:0.010000000000000009\n",
      "Averaged rejection steps : 1.0\n",
      "0.001204620086844941\n",
      "Steps:1200\n",
      "Averaged_step_size:0.010000000000000009\n",
      "Averaged rejection steps : 4.0\n",
      "Steps:1300\n",
      "Averaged_step_size:0.010000000000000009\n",
      "Averaged rejection steps : 2.0\n",
      "Steps:1400\n",
      "Averaged_step_size:0.010000000000000009\n",
      "Averaged rejection steps : 1.0\n",
      "adpative sampling\n",
      "Steps:100\n",
      "Averaged_step_size:0.07855167211278988\n",
      "Averaged rejection steps : 3.0\n",
      "Steps:200\n",
      "Averaged_step_size:0.07069650490151112\n",
      "Averaged rejection steps : 5.0\n",
      "Steps:300\n",
      "Averaged_step_size:0.06362685441136036\n",
      "Averaged rejection steps : 1.0\n",
      "0.0027006449001463653\n",
      "Steps:400\n",
      "Averaged_step_size:0.09697737297875415\n",
      "Averaged rejection steps : 1.0\n",
      "3.3206530478401075e-05\n",
      "4.0700954683212245e-05\n",
      "Steps:500\n",
      "Averaged_step_size:0.04638397686588188\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:600\n",
      "Averaged_step_size:0.03757102126136451\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:700\n",
      "Averaged_step_size:0.08727963568087965\n",
      "Averaged rejection steps : 2.0\n",
      "0.0017933880285998381\n",
      "Steps:800\n",
      "Averaged_step_size:0.07069650490151279\n",
      "Averaged rejection steps : 1.0\n",
      "0.001706293852070723\n",
      "Steps:900\n",
      "Averaged_step_size:0.05153775207320309\n",
      "Averaged rejection steps : 1.0\n",
      "0.0019165993495162236\n",
      "Steps:1000\n",
      "Averaged_step_size:0.0636268544113622\n",
      "Averaged rejection steps : 4.0\n",
      "Steps:1100\n",
      "Averaged_step_size:0.06362685441136241\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:1200\n",
      "Averaged_step_size:0.07069650490151425\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:1300\n",
      "Averaged_step_size:0.07855167211279403\n",
      "Averaged rejection steps : 1.0\n",
      "Steps:1400\n",
      "Averaged_step_size:0.05726416897022716\n",
      "Averaged rejection steps : 1.0\n"
     ]
    }
   ],
   "source": [
    "def funnel_sampler(seed, dimension, numIter, numSamples, initialStep):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    Target = target_funnel(dimension)\n",
    "    \n",
    "    # To Do: double check this formula\n",
    "    hatC = (1 + Target.alpha) * (1 / Target.alpha)**(Target.alpha / (1 + Target.alpha)) * (1 / np.pi)**(2 / (1 + Target.alpha)) * 2**((-1 - 2 * Target.alpha) / (1 + Target.alpha))\n",
    "    min_step_size = hatC / (120 * np.log(6 / 0.01) / np.log(2) * Target.L_alpha * np.sqrt(Target.dimension))\n",
    "    print(f\"min_step_size={min_step_size}\")\n",
    "\n",
    "    Xsamples_adaptive0, step_sizes0 = proximal_sampler(initialStep, numSamples, numIter, f=Target, fixed=False)\n",
    "    \n",
    "    Xsamples_adaptive1, step_sizes1 = proximal_sampler(initialStep, numSamples, numIter, f=Target, fixed=False, adjusted_size=50)\n",
    "    Xsamples_adaptive2, step_sizes2 = proximal_sampler(initialStep, numSamples, numIter, f=Target, fixed=False, adjusted_size=100)\n",
    "    \n",
    "    Xsamples_adaptive3, step_sizes3 = proximal_sampler(initialStep, numSamples, numIter, f=Target, fixed=False, tolerance=0.1)\n",
    "    Xsamples_adaptive4, step_sizes4 = proximal_sampler(initialStep, numSamples, numIter, f=Target, fixed=False, tolerance=0.001)\n",
    "    \n",
    "    Xsamples_adaptive5, step_sizes5 = proximal_sampler(initialStep, numSamples, numIter, f=Target, fixed=False, reduce=0.1)\n",
    "    Xsamples_adaptive6, step_sizes6 = proximal_sampler(initialStep, numSamples, numIter, f=Target, fixed=False, reduce=0.9)\n",
    "\n",
    "\n",
    "    direction = np.random.multivariate_normal(mean=np.zeros(dimension), cov=np.identity(dimension), size=1)\n",
    "    direction = np.transpose(direction) / np.linalg.norm(direction, ord=2)\n",
    "    \n",
    "    realSamples = np.zeros([200000, dimension])\n",
    "    for i in range(np.shape(realSamples)[0]):\n",
    "        realSamples[i, :] = Target.samplesTarget()\n",
    "    \n",
    "    bin_num = 500\n",
    "    histY, bin_edges_Y = np.histogram(np.matmul(realSamples, direction), bins=bin_num, density=True)\n",
    "\n",
    "    num_iter = numIter\n",
    "    number_samples_hist = int(0.2 * num_iter)\n",
    "    min_number_samples_hist = int(0.1 * num_iter)\n",
    "    number_hist = 100\n",
    "    bin_size = int((number_samples_hist - min_number_samples_hist) / 100)\n",
    "    index_hist = np.linspace(number_samples_hist, num_iter, number_hist).astype(int)\n",
    "\n",
    "    def calculate_distances(Xsamples):\n",
    "        distances_random = np.zeros(number_hist)\n",
    "        projected_sample_random = np.matmul(Xsamples, direction)\n",
    "        for i in range(number_hist):\n",
    "            distances_random[i] = TV_estimation(projected_sample_random[0, min_number_samples_hist:index_hist[i]], histY, bin_edges_Y, bin_num)\n",
    "        return 0.5 * distances_random\n",
    "\n",
    "    results = {\n",
    "        'default': calculate_distances(Xsamples_adaptive0),\n",
    "        'size50': calculate_distances(Xsamples_adaptive1),\n",
    "        'size100': calculate_distances(Xsamples_adaptive2),\n",
    "        'tol0.1': calculate_distances(Xsamples_adaptive3),\n",
    "        'tol0.001': calculate_distances(Xsamples_adaptive4),\n",
    "        'reduce0.1': calculate_distances(Xsamples_adaptive5),\n",
    "        'reduce0.9': calculate_distances(Xsamples_adaptive6)\n",
    "    }\n",
    "\n",
    "    return results, step_sizes0, index_hist\n",
    "\n",
    "def run_experiments(seeds, dimension, numIter, numSamples, initialStep):\n",
    "    all_results = {\n",
    "        'default': [],\n",
    "        'size50': [],\n",
    "        'size100': [],\n",
    "        'tol0.1': [],\n",
    "        'tol0.001': [],\n",
    "        'reduce0.1': [],\n",
    "        'reduce0.9': []\n",
    "    }\n",
    "    all_step_sizes = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        results, step_sizes, index_hist = funnel_sampler(seed, dimension, numIter, numSamples, initialStep)\n",
    "        for key in results:\n",
    "            all_results[key].append(results[key])\n",
    "        all_step_sizes.append(step_sizes)\n",
    "    \n",
    "    mean_results = {}\n",
    "    std_results = {}\n",
    "    for key in all_results:\n",
    "        mean_results[key] = np.mean(all_results[key], axis=0)\n",
    "        std_results[key] = np.std(all_results[key], axis=0)\n",
    "    \n",
    "    mean_step_sizes = np.mean(all_step_sizes, axis=0)\n",
    "    std_step_sizes = np.std(all_step_sizes, axis=0)\n",
    "\n",
    "    np.save('ab_funnel_TV.npy', all_results)\n",
    "    np.save('ab_funnel_size.npy', all_step_sizes)\n",
    "    \n",
    "    return mean_results, std_results, index_hist, mean_step_sizes, std_step_sizes\n",
    "\n",
    "seeds = [i for i in range(3)]\n",
    "dimension = 128\n",
    "numIter = 1500\n",
    "numSamples = 1\n",
    "initialStep = 10\n",
    "\n",
    "mean_results, std_results, index_hist, mean_step_sizes, std_step_sizes = run_experiments(seeds, dimension, numIter, numSamples, initialStep)\n",
    "\n",
    "plt.figure(figsize=(5, 6))\n",
    "for key in mean_results:\n",
    "    line, = plt.plot(index_hist, mean_results[key])\n",
    "    temp_mean = mean_results[key]\n",
    "    temp_mean *= 2 if np.all(temp_mean == 0.5) else True\n",
    "    temp_std = std_results[key]\n",
    "    plt.errorbar(index_hist[np.arange(0, len(index_hist), 10)], temp_mean[np.arange(0, len(index_hist), 10)], \n",
    "                 yerr=2*temp_std[np.arange(0, len(index_hist), 10)], label=key, fmt='o', color = line.get_color(),markersize=4)\n",
    "\n",
    "    \n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('TV along a random direction')\n",
    "plt.legend(fontsize='small', loc='lower left')\n",
    "plt.savefig('ab_funnel_TV.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(5, 6))\n",
    "mean_step = mean_step_sizes[0,:]\n",
    "plt.plot(range(len(mean_step)), mean_step)\n",
    "print(f'max of std size:{max(std_step_sizes[0,:])}')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Averaged step sizes')\n",
    "plt.axhline(y=0.625, linestyle='--', label='0.625', color='r')\n",
    "plt.axhline(y=1.25, linestyle='--', label='1.25', color='g')\n",
    "plt.legend()\n",
    "plt.savefig('ab_funnel_size.pdf')\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
