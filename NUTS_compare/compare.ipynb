{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that generates samples approximate RGO. The target is defined in Potential class.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from utils import target_func, estimate_W2_Gaussian\n",
    "from matplotlib.ticker import MultipleLocator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function as the original approximate RGO\n",
    "def generate_samples(step_size, x_y, f):\n",
    "    dimension = f.dimension\n",
    "    ite = 0\n",
    "    while True:\n",
    "        samples = np.random.multivariate_normal(mean = x_y, cov = step_size * np.identity(dimension), size = 2)\n",
    "        # Compute the acceptance probability\n",
    "        gradient = f.firstOrder(x_y)\n",
    "        a = f.zeroOrder(samples[0,:])-np.dot(gradient,samples[0,:])\n",
    "        b = f.zeroOrder(samples[1,:])-np.dot(gradient,samples[1,:])\n",
    "        # The code works even when rho is inf. One can also take the log transformation\n",
    "        rho = np.exp(b-a)\n",
    "        u = np.random.uniform(0,1)\n",
    "        ite = ite + 1\n",
    "        if u < rho/2:\n",
    "            break\n",
    "    return samples[0,:],ite\n",
    "\n",
    "# Define a function that estimates the local step size\n",
    "def estimate_step_size(step_size, tolerance, y, f):\n",
    "    dimension = f.dimension\n",
    "    # Compute the desired subexponential parameter\n",
    "    x_y = f.solve1(y, step_size)\n",
    "    testFunction = lambda C : np.mean(np.exp(np.abs(Y)**(2/(1+f.alpha))/C))-2\n",
    "    while True:\n",
    "        # Generate random samples from a Gaussian distribution: \\exp^{-(x-x_y)^2/(2\\step_size)}\n",
    "        samples = np.random.multivariate_normal(mean = x_y, cov = step_size * np.identity(dimension), size = 200)\n",
    "        Y = np.zeros(100)\n",
    "        for i in range(100):\n",
    "            gradient = f.firstOrder(x_y)\n",
    "            a = f.zeroOrder(samples[i])-np.dot(gradient,samples[i])\n",
    "            b = f.zeroOrder(samples[i+100])-np.dot(gradient,samples[i+100])\n",
    "            Y[i] = b-a\n",
    "        # Estimate the subexponential parameter of Y: find the smallest C>0 such that E[\\exp^{\\abs(Y)/C}] \\leq 2 by binary search for smooth potentials\n",
    "        # Initialize the interval\n",
    "        left = 0\n",
    "        right = dimension**(f.alpha/(f.alpha+1)) # The estimated upper bound of the subexponential parameter\n",
    "        while testFunction(right)>0:\n",
    "            left = right\n",
    "            right = 2*right\n",
    "        # Initialize the middle point\n",
    "        mid = (left+right)/2\n",
    "        # Initialize the value of the function\n",
    "        f_mid = testFunction(mid)\n",
    "        while abs(f_mid) > 1e-2:\n",
    "            if f_mid > 0:\n",
    "                left = mid\n",
    "            else:\n",
    "                right = mid\n",
    "            mid = (left+right)/2\n",
    "            f_mid =  testFunction(mid)\n",
    "        # reduce this 10\n",
    "        if mid < 1 / ( np.log(6/tolerance) / np.log(2)  * 0.05) :\n",
    "            break\n",
    "        else:\n",
    "            step_size = step_size / 2\n",
    "            x_y = f.solve1(y, step_size)\n",
    "    return step_size, x_y\n",
    "\n",
    "# Define the outer loop of proximal sampler\n",
    "def proximal_sampler(initial_step_size, num_samples, num_iter, f, fixed):\n",
    "    dimension = f.dimension\n",
    "\n",
    "    samples = np.zeros([num_samples,num_iter,dimension])\n",
    "    Ysamples = np.zeros([num_samples,dimension])\n",
    "    rejections = np.zeros([num_samples, num_iter])\n",
    "    \n",
    "    # Initialize the samples for both fxied and adaptive versions\n",
    "    samples[:,0,:] = np.random.multivariate_normal(mean =  np.zeros(dimension), cov =  np.identity(dimension), size = num_samples)\n",
    "    for j in range(num_samples):\n",
    "        Ysamples[j,:] = np.random.multivariate_normal(mean = samples[j,0,:], cov = initial_step_size * np.identity(dimension), size = 1)\n",
    "    \n",
    "    if fixed == True:    \n",
    "        print(f'fixed sampling')\n",
    "        for i in range(1,num_iter):\n",
    "            for j in range(num_samples):\n",
    "                x_y = f.solve1(Ysamples[j,:], initial_step_size)\n",
    "                samples[j,i,:],ite = generate_samples(initial_step_size, x_y, f)\n",
    "                Ysamples[j,:] = np.random.multivariate_normal(mean = samples[j,i,:], cov = initial_step_size * np.identity(dimension), size = 1) \n",
    "                rejections[j,i] = ite\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Steps:{i}\")\n",
    "                if f.times2 > 0:\n",
    "                    print(f\"Averaged optimization steps of the new one: {f.ite2/f.times2}\")\n",
    "                print(f\"Averaged rejection steps : {np.mean(rejections[:,i])}\")\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    if fixed == False:\n",
    "        print(f'adpative sampling')\n",
    "        step_sizes = np.zeros([num_samples,num_iter])\n",
    "        step_sizes[:,0] = initial_step_size\n",
    "        for i in range(1,num_iter):\n",
    "            for j in range(num_samples):\n",
    "                # if i < 100 or (i >= 100 and np.random.uniform(0,1) < 0.001):\n",
    "                if True:\n",
    "                    step_size, x_y = estimate_step_size(2*step_sizes[j,i-1], 1e-2, Ysamples[j,:], f)\n",
    "                else:\n",
    "                    x_y = f.solve1(Ysamples[j,:], step_sizes[j,i-1])\n",
    "                    step_size = step_sizes[j,i-1]\n",
    "                samples[j,i,:],ite = generate_samples(step_size, x_y, f)\n",
    "                Ysamples[j,:] = np.random.multivariate_normal(mean = samples[j,i,:], cov = step_size * np.identity(dimension), size = 1)  \n",
    "                step_sizes[j,i] = step_size\n",
    "                rejections[j,i] = ite  \n",
    "            \n",
    "            # statistics for the first sample\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Steps:{i}\")\n",
    "                print(f\"Averaged_step_size:{np.mean(step_sizes[:,i])}\")\n",
    "                if f.times2 > 0:\n",
    "                    print(f\"Averaged optimization steps of the new one: {f.ite2/f.times2}\")\n",
    "                print(f\"Averaged rejection steps : {np.mean(rejections[:,i])}\")\n",
    "    return samples, step_sizes\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L=1.0\n",
      "min_step_size=0.00014371191339995835\n",
      "adpative sampling\n",
      "1.4648755545712304e-08\n",
      "9.423623133841114e-08\n",
      "1.4082721900161421e-08\n",
      "L=1.0\n",
      "min_step_size=0.00010161966850240442\n",
      "adpative sampling\n",
      "5.406809838445531e-08\n",
      "L=1.0\n",
      "min_step_size=7.185595669997918e-05\n",
      "adpative sampling\n",
      "9.169426194297855e-09\n",
      "L=1.0\n",
      "min_step_size=5.080983425120221e-05\n",
      "adpative sampling\n",
      "3.2370601705715194e-06\n",
      "9.914636724598073e-07\n",
      "6.933940883435708e-08\n",
      "3.997731790006035e-08\n",
      "6.091285316788424e-08\n",
      "L=1.0\n",
      "min_step_size=3.592797834998959e-05\n",
      "adpative sampling\n"
     ]
    }
   ],
   "source": [
    "def Gaussian_sampler(seed, dimension, numIter, numSamples, initialStep):\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    Target = target_func(dimension, if_simple = True)\n",
    "    \n",
    "    # To Do: double check this formula\n",
    "    hatC = (1+Target.alpha)*(1/Target.alpha)**(Target.alpha/(1+Target.alpha))*(1/np.pi)**(2/(1+Target.alpha))*2**((-1-2*Target.alpha)/(1+Target.alpha))\n",
    "    min_step_size = hatC/(120*np.log(6/0.01)/np.log(2)*Target.L_alpha*np.sqrt(Target.dimension))\n",
    "    print(f\"min_step_size={min_step_size}\")\n",
    "    \n",
    "    # realSamples = np.zeros([200000, dimension])\n",
    "    # for i in range(np.shape(realSamples)[0]):\n",
    "    #         realSamples[i,:] = Target.samplesTarget()\n",
    "    # plt.hist(realSamples[:,0])\n",
    "    # plt.show()\n",
    "    # plt.close()\n",
    "    \n",
    "    Xsamples_adaptive ,step_sizes = proximal_sampler(initialStep, numSamples, numIter, f = Target, fixed = False)\n",
    "    \n",
    "    W2_distances = estimate_W2_Gaussian(Xsamples_adaptive,Target.mean, np.identity(dimension)) # the true cov is I_d\n",
    "\n",
    "    \n",
    "    return W2_distances, step_sizes\n",
    "\n",
    "num_iters = 21\n",
    "plt.figure(figsize = (5,6))\n",
    "sizes = np.zeros([5,num_iters])\n",
    "for one_dimen in [2,4,8,16,32]:\n",
    "    W2_distances, step_sizes = Gaussian_sampler(5,one_dimen,num_iters,50,0.1)\n",
    "    plt.plot(list(range(1, num_iters)), W2_distances[1:],label = f'd = {one_dimen}')\n",
    "    sizes[int(np.log2(one_dimen)-1),:] = np.mean(step_sizes,axis = 0)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Estiamted W2 distance')\n",
    "ax = plt.gca() \n",
    "ax.xaxis.set_major_locator(MultipleLocator(4))  \n",
    "plt.legend()\n",
    "plt.savefig('W2_dimension.pdf')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize = (5,6))\n",
    "for i in range(sizes.shape[0]):\n",
    "    one_dimen = 2**(i+1)\n",
    "    plt.plot(list(range(1, num_iters)),sizes[i,1:],label = f'd = {one_dimen}')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Average step size')\n",
    "ax = plt.gca() \n",
    "ax.xaxis.set_major_locator(MultipleLocator(4))  \n",
    "plt.legend()\n",
    "plt.savefig('step_dimension.pdf')\n",
    "plt.close()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
