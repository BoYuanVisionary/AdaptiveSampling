{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that generates samples approximate RGO. The target is defined in Potential class.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from utils import target_func, estimate_W2_Gaussian, target_funnel\n",
    "from matplotlib.ticker import MultipleLocator \n",
    "from NUTS import nuts6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function as the original approximate RGO\n",
    "def generate_samples(step_size, x_y, f):\n",
    "    dimension = f.dimension\n",
    "    ite = 0\n",
    "    while True:\n",
    "        samples = np.random.multivariate_normal(mean = x_y, cov = step_size * np.identity(dimension), size = 2)\n",
    "        # Compute the acceptance probability\n",
    "        gradient = f.firstOrder(x_y)\n",
    "        a = f.zeroOrder(samples[0,:])-np.dot(gradient,samples[0,:])\n",
    "        b = f.zeroOrder(samples[1,:])-np.dot(gradient,samples[1,:])\n",
    "        # The code works even when rho is inf. One can also take the log transformation\n",
    "        rho = np.exp(b-a)\n",
    "        u = np.random.uniform(0,1)\n",
    "        ite = ite + 1\n",
    "        if u < rho/2:\n",
    "            break\n",
    "    return samples[0,:],ite\n",
    "\n",
    "# Define a function that estimates the local step size\n",
    "def estimate_step_size(step_size, tolerance, y, f):\n",
    "    dimension = f.dimension\n",
    "    # Compute the desired subexponential parameter\n",
    "    x_y = f.solve1(y, step_size)\n",
    "    testFunction = lambda C : np.mean(np.exp(np.abs(Y)**(2/(1+f.alpha))/C))-2\n",
    "    while True:\n",
    "        # Generate random samples from a Gaussian distribution: \\exp^{-(x-x_y)^2/(2\\step_size)}\n",
    "        samples = np.random.multivariate_normal(mean = x_y, cov = step_size * np.identity(dimension), size = 200)\n",
    "        Y = np.zeros(100)\n",
    "        for i in range(100):\n",
    "            gradient = f.firstOrder(x_y)\n",
    "            a = f.zeroOrder(samples[i])-np.dot(gradient,samples[i])\n",
    "            b = f.zeroOrder(samples[i+100])-np.dot(gradient,samples[i+100])\n",
    "            Y[i] = b-a\n",
    "        # Estimate the subexponential parameter of Y: find the smallest C>0 such that E[\\exp^{\\abs(Y)/C}] \\leq 2 by binary search for smooth potentials\n",
    "        # Initialize the interval\n",
    "        left = 0\n",
    "        right = dimension**(f.alpha/(f.alpha+1)) # The estimated upper bound of the subexponential parameter\n",
    "        while testFunction(right)>0:\n",
    "            left = right\n",
    "            right = 2*right\n",
    "        # Initialize the middle point\n",
    "        mid = (left+right)/2\n",
    "        # Initialize the value of the function\n",
    "        f_mid = testFunction(mid)\n",
    "        while abs(f_mid) > 1e-2:\n",
    "            if f_mid > 0:\n",
    "                left = mid\n",
    "            else:\n",
    "                right = mid\n",
    "            mid = (left+right)/2\n",
    "            f_mid =  testFunction(mid)\n",
    "        if mid < 1 / ( np.log(6/tolerance) / np.log(2)  * 0.5) :\n",
    "            break\n",
    "        else:\n",
    "            step_size = step_size / 2\n",
    "            x_y = f.solve1(y, step_size)\n",
    "    return step_size, x_y\n",
    "\n",
    "# Define the outer loop of proximal sampler\n",
    "def proximal_sampler(initial_step_size, num_samples, num_iter, f, fixed):\n",
    "    dimension = f.dimension\n",
    "\n",
    "    samples = np.zeros([num_samples,num_iter,dimension])\n",
    "    Ysamples = np.zeros([num_samples,dimension])\n",
    "    rejections = np.zeros([num_samples, num_iter])\n",
    "    step_sizes = np.zeros([num_samples,num_iter])\n",
    "\n",
    "    \n",
    "    # Initialize the samples for both fxied and adaptive versions\n",
    "    diagonal_values = np.linspace(1, 2, dimension) \n",
    "    samples[:,0,:] = np.random.multivariate_normal(mean =  2 + np.zeros(dimension), cov = np.diag(diagonal_values), size = num_samples)\n",
    "    for j in range(num_samples):\n",
    "        Ysamples[j,:] = np.random.multivariate_normal(mean =  np.zeros(dimension), cov = np.identity(dimension), size = 1)\n",
    "        if fixed == False:\n",
    "            step_size, x_y = estimate_step_size(initial_step_size, 1e-2, Ysamples[j,:], f)\n",
    "            step_sizes[j,0] = step_size\n",
    "\n",
    "    \n",
    "    if fixed == True:    \n",
    "        print(f'fixed sampling')\n",
    "        for i in range(1,num_iter):\n",
    "            for j in range(num_samples):\n",
    "                x_y = f.solve1(Ysamples[j,:], initial_step_size)\n",
    "                samples[j,i,:],ite = generate_samples(initial_step_size, x_y, f)\n",
    "                Ysamples[j,:] = np.random.multivariate_normal(mean = samples[j,i,:], cov = initial_step_size * np.identity(dimension), size = 1) \n",
    "                rejections[j,i] = ite\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Steps:{i}\")\n",
    "                if f.times2 > 0:\n",
    "                    print(f\"Averaged optimization steps of the new one: {f.ite2/f.times2}\")\n",
    "                print(f\"Averaged rejection steps : {np.mean(rejections[:,i])}\")\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    if fixed == False:\n",
    "        print(f'adpative sampling')\n",
    "        for i in range(1,num_iter):\n",
    "            for j in range(num_samples):\n",
    "                # if i < 100 or (i >= 100 and np.random.uniform(0,1) < 0.001):\n",
    "                if True:\n",
    "                    step_size, x_y = estimate_step_size(2*step_sizes[j,i-1], 1e-2, Ysamples[j,:], f)\n",
    "                else:\n",
    "                    x_y = f.solve1(Ysamples[j,:], step_sizes[j,i-1])\n",
    "                    step_size = step_sizes[j,i-1]\n",
    "                samples[j,i,:],ite = generate_samples(step_size, x_y, f)\n",
    "                Ysamples[j,:] = np.random.multivariate_normal(mean = samples[j,i,:], cov = step_size * np.identity(dimension), size = 1)  \n",
    "                step_sizes[j,i] = step_size\n",
    "                rejections[j,i] = ite  \n",
    "            \n",
    "            # statistics for the first sample\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Steps:{i}\")\n",
    "                print(f\"Averaged_step_size:{np.mean(step_sizes[:,i])}\")\n",
    "                if f.times2 > 0:\n",
    "                    print(f\"Averaged optimization steps of the new one: {f.ite2/f.times2}\")\n",
    "                print(f\"Averaged rejection steps : {np.mean(rejections[:,i])}\")\n",
    "    return samples, step_sizes\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_sampler(index_trail, one_dimen, num_iters, num_chains, Madapt):\n",
    "    samples = test_nuts6(one_dimen, target_funnel(one_dimen), num_chains, num_iters, Madapt)\n",
    "    W2_distances = estimate_W2_Gaussian(samples,np.zeros(one_dimen), np.identity(one_dimen)) # the true cov is I_d\n",
    "\n",
    "    return W2_distances\n",
    "\n",
    "def test_nuts6(dim, target_funnel_instance, num_chains=50, M=14, Madapt=5):\n",
    "    \"\"\" Example usage of nuts6: sampling a Gaussian distribution with mean zero and identity covariance matrix \"\"\"\n",
    "\n",
    "    class Counter:\n",
    "        def __init__(self, c=0):\n",
    "            self.c = c\n",
    "            \n",
    "    def normal(theta):\n",
    "        \"\"\"\n",
    "        Target distribution: Gaussian with mean zero and identity covariance matrix.\n",
    "        \"\"\"\n",
    "        A = np.eye(dim)\n",
    "        counter.c += 1\n",
    "        grad = -np.dot(theta, A)\n",
    "        logp = 0.5 * np.dot(grad, theta.T)\n",
    "        return logp, grad\n",
    "    \n",
    "    def funnel(theta):\n",
    "        \"\"\"\n",
    "        Target distribution: Gaussian with mean zero and identity covariance matrix.\n",
    "        \"\"\"\n",
    "        counter.c += 1\n",
    "        grad = -target_funnel_instance.firstOrder(theta)\n",
    "        logp = -target_funnel_instance.zeroOrder(theta)\n",
    "        return logp, grad\n",
    "\n",
    "    all_samples = []\n",
    "    for chain in range(num_chains):\n",
    "        counter = Counter()\n",
    "        D = dim\n",
    "        diagonal_values = np.linspace(1, 2, D) \n",
    "        theta0 = np.random.multivariate_normal( 2 + np.zeros(D), np.diag(diagonal_values), 1)\n",
    "        theta0 = theta0.ravel()\n",
    "        delta = 0.2\n",
    "\n",
    "        samples, lnprob, epsilon = nuts6(funnel, M, Madapt, theta0, delta)\n",
    "        all_samples.append(samples)\n",
    "\n",
    "    all_samples = np.array(all_samples)\n",
    "    return all_samples\n",
    "\n",
    "# Parameters\n",
    "num_iters = 15\n",
    "Madapt = 5\n",
    "trails = 10\n",
    "num_chains = 50\n",
    "overall_results = np.zeros([trails, 1, num_iters+Madapt])\n",
    "\n",
    "\n",
    "for index_trail in range(trails):\n",
    "    for dim_index, one_dimen in enumerate([128]):\n",
    "        W2_distances = Gaussian_sampler(index_trail, one_dimen, num_iters, num_chains, Madapt)\n",
    "        print(f\"dim:{one_dimen}, 'W2:{ W2_distances[0]}'\")\n",
    "        overall_results[index_trail, dim_index, :] = W2_distances\n",
    "\n",
    "# Plot W2 distances\n",
    "W2_mean = np.mean(overall_results, axis=0)\n",
    "W2_std = np.std(overall_results, axis=0)\n",
    "plt.figure(figsize=(5, 5))\n",
    "for dim_index in range(overall_results.shape[1]):\n",
    "    y = W2_mean[dim_index, :]\n",
    "    error = 2 * W2_std[dim_index, :]\n",
    "    one_dimen = 2 ** (dim_index + 1)\n",
    "    plt.errorbar(list(range(len(y))), y, yerr=error, label=f'd = {one_dimen}')\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Estimated W2 distance')\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(MultipleLocator(4))\n",
    "plt.legend()\n",
    "plt.savefig('NUTS_W2_dimension.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L=1.0\n",
      "min_step_size=1.7963989174994794e-05\n",
      "1.3472383724322645e-06\n",
      "adpative sampling\n",
      "2.089439766423649e-06\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m one_dimen \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m128\u001b[39m]:\n\u001b[1;32m     28\u001b[0m         W2_distances, step_sizes \u001b[38;5;241m=\u001b[39m Gaussian_sampler(index_trail,one_dimen,num_iters,num_sample,\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m         overall_results[index_trail,\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mlog2(one_dimen)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m),:] \u001b[38;5;241m=\u001b[39m  W2_distances\n\u001b[1;32m     30\u001b[0m         overall_sizes[index_trail, \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mlog2(one_dimen)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m),:] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(step_sizes,axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     31\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madaptive_W2.npy\u001b[39m\u001b[38;5;124m'\u001b[39m,overall_results)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "def Gaussian_sampler(seed, dimension, numIter, numSamples, initialStep):\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    Target = target_func(dimension, if_simple = True)\n",
    "    \n",
    "    # To Do: double check this formula\n",
    "    hatC = (1+Target.alpha)*(1/Target.alpha)**(Target.alpha/(1+Target.alpha))*(1/np.pi)**(2/(1+Target.alpha))*2**((-1-2*Target.alpha)/(1+Target.alpha))\n",
    "    min_step_size = hatC/(120*np.log(6/0.01)/np.log(2)*Target.L_alpha*np.sqrt(Target.dimension))\n",
    "    print(f\"min_step_size={min_step_size}\")\n",
    "        \n",
    "    Xsamples_adaptive ,step_sizes = proximal_sampler(initialStep, numSamples, numIter, f = Target, fixed = False)\n",
    "    W2_distances = estimate_W2_Gaussian(Xsamples_adaptive,Target.mean, np.identity(dimension)) # the true cov is I_d\n",
    "\n",
    "    \n",
    "    return W2_distances, step_sizes\n",
    "\n",
    "num_iters = 20\n",
    "trails = 10\n",
    "overall_results = np.zeros([trails,1,num_iters])\n",
    "overall_sizes = np.zeros([trails,1,num_iters])\n",
    "num_sample = 50\n",
    "\n",
    "for index_trail in range(trails):\n",
    "    sizes = np.zeros([5,num_iters])\n",
    "    for one_dimen in [128]:\n",
    "        W2_distances, step_sizes = Gaussian_sampler(index_trail,one_dimen,num_iters,num_sample,10)\n",
    "        overall_results[index_trail,int(np.log2(one_dimen)-7),:] =  W2_distances\n",
    "        overall_sizes[index_trail, int(np.log2(one_dimen)-7),:] = np.mean(step_sizes,axis = 0)\n",
    "np.save('adaptive_W2.npy',overall_results)\n",
    "np.save('adaptive_size.npy',overall_sizes)\n",
    "W2_mean = np.mean(overall_results,axis = 0)\n",
    "w2_std = np.std(overall_results,axis = 0)\n",
    "plt.figure(figsize = (5,5))\n",
    "for dimen_index in range(overall_results.shape[1]):\n",
    "    y = W2_mean[dimen_index,:]\n",
    "    error = 2* w2_std[dimen_index,:]\n",
    "    one_dimen = 2**(dimen_index+1)\n",
    "    plt.errorbar(list(range(len(y))), y, yerr=error, label=f'd = {one_dimen}')\n",
    "\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Estiamted W2 distance')\n",
    "ax = plt.gca() \n",
    "ax.xaxis.set_major_locator(MultipleLocator(4))  \n",
    "plt.legend()\n",
    "plt.savefig('W2_dimension.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "size_mean = np.mean(overall_sizes,axis = 0)\n",
    "size_std = np.std(overall_sizes,axis = 0)\n",
    "plt.figure(figsize = (5,5))\n",
    "for dimen_index in range(overall_sizes.shape[1]):\n",
    "    y = size_mean[dimen_index,:]\n",
    "    error = 2* size_std[dimen_index,:]\n",
    "    one_dimen = 2**(dimen_index+1)\n",
    "    plt.errorbar(list(range(len(y))), y, yerr=error, \n",
    "                    label=f'd = {one_dimen}')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Average step size')\n",
    "ax = plt.gca() \n",
    "ax.xaxis.set_major_locator(MultipleLocator(4))  \n",
    "plt.legend()\n",
    "plt.savefig('step_dimension.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "fileId": "b690acb2-3069-4b27-b35b-e29072ccba06",
  "filePath": "/mlx_devbox/users/byuan.48/playground/arnold_workspace_root/projects/AdaptiveSampling/NUTS_compare/compare.ipynb",
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
