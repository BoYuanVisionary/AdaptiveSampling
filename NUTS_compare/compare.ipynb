{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that generates samples approximate RGO. The target is defined in Potential class.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from utils import target_func, estimate_W2_Gaussian\n",
    "from matplotlib.ticker import MultipleLocator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function as the original approximate RGO\n",
    "def generate_samples(step_size, x_y, f):\n",
    "    dimension = f.dimension\n",
    "    ite = 0\n",
    "    while True:\n",
    "        samples = np.random.multivariate_normal(mean = x_y, cov = step_size * np.identity(dimension), size = 2)\n",
    "        # Compute the acceptance probability\n",
    "        gradient = f.firstOrder(x_y)\n",
    "        a = f.zeroOrder(samples[0,:])-np.dot(gradient,samples[0,:])\n",
    "        b = f.zeroOrder(samples[1,:])-np.dot(gradient,samples[1,:])\n",
    "        # The code works even when rho is inf. One can also take the log transformation\n",
    "        rho = np.exp(b-a)\n",
    "        u = np.random.uniform(0,1)\n",
    "        ite = ite + 1\n",
    "        if u < rho/2:\n",
    "            break\n",
    "    return samples[0,:],ite\n",
    "\n",
    "# Define a function that estimates the local step size\n",
    "def estimate_step_size(step_size, tolerance, y, f):\n",
    "    dimension = f.dimension\n",
    "    # Compute the desired subexponential parameter\n",
    "    x_y = f.solve1(y, step_size)\n",
    "    testFunction = lambda C : np.mean(np.exp(np.abs(Y)**(2/(1+f.alpha))/C))-2\n",
    "    while True:\n",
    "        # Generate random samples from a Gaussian distribution: \\exp^{-(x-x_y)^2/(2\\step_size)}\n",
    "        samples = np.random.multivariate_normal(mean = x_y, cov = step_size * np.identity(dimension), size = 200)\n",
    "        Y = np.zeros(100)\n",
    "        for i in range(100):\n",
    "            gradient = f.firstOrder(x_y)\n",
    "            a = f.zeroOrder(samples[i])-np.dot(gradient,samples[i])\n",
    "            b = f.zeroOrder(samples[i+100])-np.dot(gradient,samples[i+100])\n",
    "            Y[i] = b-a\n",
    "        # Estimate the subexponential parameter of Y: find the smallest C>0 such that E[\\exp^{\\abs(Y)/C}] \\leq 2 by binary search for smooth potentials\n",
    "        # Initialize the interval\n",
    "        left = 0\n",
    "        right = dimension**(f.alpha/(f.alpha+1)) # The estimated upper bound of the subexponential parameter\n",
    "        while testFunction(right)>0:\n",
    "            left = right\n",
    "            right = 2*right\n",
    "        # Initialize the middle point\n",
    "        mid = (left+right)/2\n",
    "        # Initialize the value of the function\n",
    "        f_mid = testFunction(mid)\n",
    "        while abs(f_mid) > 1e-2:\n",
    "            if f_mid > 0:\n",
    "                left = mid\n",
    "            else:\n",
    "                right = mid\n",
    "            mid = (left+right)/2\n",
    "            f_mid =  testFunction(mid)\n",
    "        # reduce this 10\n",
    "        if mid < 1 / ( np.log(6/tolerance) / np.log(2)  * 0.05) :\n",
    "            break\n",
    "        else:\n",
    "            step_size = step_size / 2\n",
    "            x_y = f.solve1(y, step_size)\n",
    "    return step_size, x_y\n",
    "\n",
    "# Define the outer loop of proximal sampler\n",
    "def proximal_sampler(initial_step_size, num_samples, num_iter, f, fixed):\n",
    "    dimension = f.dimension\n",
    "\n",
    "    samples = np.zeros([num_samples,num_iter,dimension])\n",
    "    Ysamples = np.zeros([num_samples,dimension])\n",
    "    rejections = np.zeros([num_samples, num_iter])\n",
    "    \n",
    "    # Initialize the samples for both fxied and adaptive versions\n",
    "    samples[:,0,:] = np.random.multivariate_normal(mean =  np.zeros(dimension), cov =  np.identity(dimension), size = num_samples)\n",
    "    for j in range(num_samples):\n",
    "        Ysamples[j,:] = np.random.multivariate_normal(mean = samples[j,0,:], cov = initial_step_size * np.identity(dimension), size = 1)\n",
    "    \n",
    "    if fixed == True:    \n",
    "        print(f'fixed sampling')\n",
    "        for i in range(1,num_iter):\n",
    "            for j in range(num_samples):\n",
    "                x_y = f.solve1(Ysamples[j,:], initial_step_size)\n",
    "                samples[j,i,:],ite = generate_samples(initial_step_size, x_y, f)\n",
    "                Ysamples[j,:] = np.random.multivariate_normal(mean = samples[j,i,:], cov = initial_step_size * np.identity(dimension), size = 1) \n",
    "                rejections[j,i] = ite\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Steps:{i}\")\n",
    "                if f.times2 > 0:\n",
    "                    print(f\"Averaged optimization steps of the new one: {f.ite2/f.times2}\")\n",
    "                print(f\"Averaged rejection steps : {np.mean(rejections[:,i])}\")\n",
    "        \n",
    "        return samples\n",
    "    \n",
    "    if fixed == False:\n",
    "        print(f'adpative sampling')\n",
    "        step_sizes = np.zeros([num_samples,num_iter])\n",
    "        step_sizes[:,0] = initial_step_size\n",
    "        for i in range(1,num_iter):\n",
    "            for j in range(num_samples):\n",
    "                # if i < 100 or (i >= 100 and np.random.uniform(0,1) < 0.001):\n",
    "                if True:\n",
    "                    step_size, x_y = estimate_step_size(2*step_sizes[j,i-1], 1e-2, Ysamples[j,:], f)\n",
    "                else:\n",
    "                    x_y = f.solve1(Ysamples[j,:], step_sizes[j,i-1])\n",
    "                    step_size = step_sizes[j,i-1]\n",
    "                samples[j,i,:],ite = generate_samples(step_size, x_y, f)\n",
    "                Ysamples[j,:] = np.random.multivariate_normal(mean = samples[j,i,:], cov = step_size * np.identity(dimension), size = 1)  \n",
    "                step_sizes[j,i] = step_size\n",
    "                rejections[j,i] = ite  \n",
    "            \n",
    "            # statistics for the first sample\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Steps:{i}\")\n",
    "                print(f\"Averaged_step_size:{np.mean(step_sizes[:,i])}\")\n",
    "                if f.times2 > 0:\n",
    "                    print(f\"Averaged optimization steps of the new one: {f.ite2/f.times2}\")\n",
    "                print(f\"Averaged rejection steps : {np.mean(rejections[:,i])}\")\n",
    "    return samples, step_sizes\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L=1.0\n",
      "min_step_size=0.00014371191339995835\n",
      "adpative sampling\n",
      "1.0874221352767347e-08\n",
      "4.1781184370776116e-09\n",
      "1.862292753055172e-08\n",
      "L=1.0\n",
      "min_step_size=0.00010161966850240442\n",
      "adpative sampling\n",
      "1.5884472615572737e-08\n",
      "9.892064183006265e-08\n",
      "2.170097580261599e-08\n",
      "L=1.0\n",
      "min_step_size=7.185595669997918e-05\n",
      "adpative sampling\n",
      "3.252135469305443e-08\n",
      "2.999485520539009e-08\n",
      "L=1.0\n",
      "min_step_size=5.080983425120221e-05\n",
      "adpative sampling\n",
      "4.7484518521242914e-07\n",
      "1.3109068035958592e-07\n",
      "L=1.0\n",
      "min_step_size=3.592797834998959e-05\n",
      "adpative sampling\n",
      "3.578331255939156e-07\n",
      "2.0571270498869004e-07\n",
      "4.078514040940647e-07\n",
      "3.7585902715421966e-07\n",
      "3.359498615165657e-07\n",
      "L=1.0\n",
      "min_step_size=0.00014371191339995835\n",
      "adpative sampling\n",
      "9.730191236324793e-09\n",
      "1.3253306710070836e-09\n",
      "L=1.0\n",
      "min_step_size=0.00010161966850240442\n",
      "adpative sampling\n",
      "6.263048668280892e-08\n",
      "L=1.0\n",
      "min_step_size=7.185595669997918e-05\n",
      "adpative sampling\n",
      "3.025141255850048e-07\n",
      "4.2090859439759185e-08\n",
      "1.723980127253747e-07\n",
      "4.0596490497214004e-08\n",
      "L=1.0\n",
      "min_step_size=5.080983425120221e-05\n",
      "adpative sampling\n",
      "1.4884486294447017e-07\n",
      "1.1676814658471215e-07\n",
      "L=1.0\n",
      "min_step_size=3.592797834998959e-05\n",
      "adpative sampling\n",
      "2.782360049996306e-07\n",
      "5.109632959275731e-07\n",
      "5.870182310550516e-07\n",
      "2.565967964636848e-07\n",
      "L=1.0\n",
      "min_step_size=0.00014371191339995835\n",
      "adpative sampling\n",
      "1.0527440302592358e-08\n",
      "9.913546239842074e-09\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m sizes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros([\u001b[38;5;241m5\u001b[39m,num_iters])\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m one_dimen \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m32\u001b[39m]:\n\u001b[1;32m---> 28\u001b[0m     W2_distances, step_sizes \u001b[38;5;241m=\u001b[39m \u001b[43mGaussian_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_trail\u001b[49m\u001b[43m,\u001b[49m\u001b[43mone_dimen\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_iters\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     overall_results[index_trail,\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mlog2(one_dimen)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),:] \u001b[38;5;241m=\u001b[39m  W2_distances[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     30\u001b[0m     overall_sizes[index_trail, \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mlog2(one_dimen)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),:] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(step_sizes[:,\u001b[38;5;241m1\u001b[39m:],axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 13\u001b[0m, in \u001b[0;36mGaussian_sampler\u001b[1;34m(seed, dimension, numIter, numSamples, initialStep)\u001b[0m\n\u001b[0;32m     10\u001b[0m min_step_size \u001b[38;5;241m=\u001b[39m hatC\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m120\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m6\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m*\u001b[39mTarget\u001b[38;5;241m.\u001b[39mL_alpha\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(Target\u001b[38;5;241m.\u001b[39mdimension))\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_step_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_step_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m Xsamples_adaptive ,step_sizes \u001b[38;5;241m=\u001b[39m \u001b[43mproximal_sampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitialStep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumSamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumIter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m W2_distances \u001b[38;5;241m=\u001b[39m estimate_W2_Gaussian(Xsamples_adaptive,Target\u001b[38;5;241m.\u001b[39mmean, np\u001b[38;5;241m.\u001b[39midentity(dimension)) \u001b[38;5;66;03m# the true cov is I_d\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m W2_distances, step_sizes\n",
      "Cell \u001b[1;32mIn[4], line 97\u001b[0m, in \u001b[0;36mproximal_sampler\u001b[1;34m(initial_step_size, num_samples, num_iter, f, fixed)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples):\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# if i < 100 or (i >= 100 and np.random.uniform(0,1) < 0.001):\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 97\u001b[0m         step_size, x_y \u001b[38;5;241m=\u001b[39m \u001b[43mestimate_step_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_sizes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYsamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     99\u001b[0m         x_y \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39msolve1(Ysamples[j,:], step_sizes[j,i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m, in \u001b[0;36mestimate_step_size\u001b[1;34m(step_size, tolerance, y, f)\u001b[0m\n\u001b[0;32m     28\u001b[0m Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m---> 30\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirstOrder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     a \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mzeroOrder(samples[i])\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mdot(gradient,samples[i])\n\u001b[0;32m     32\u001b[0m     b \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mzeroOrder(samples[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m100\u001b[39m])\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mdot(gradient,samples[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m100\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AdaptiveSampling\\NUTS_compare\\targets.py:63\u001b[0m, in \u001b[0;36mTargetMixture.firstOrder\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs):\n\u001b[0;32m     62\u001b[0m     firstOrders[i,:] \u001b[38;5;241m=\u001b[39m item\u001b[38;5;241m.\u001b[39mfirstOrder(x)\n\u001b[1;32m---> 63\u001b[0m     zeroOrders[i] \u001b[38;5;241m=\u001b[39m \u001b[43mitem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeroOrder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     64\u001b[0m parameters \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(np\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobs) \u001b[38;5;241m-\u001b[39m zeroOrders \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzeroOrder(x))\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmatmul(np\u001b[38;5;241m.\u001b[39mtranspose(parameters),firstOrders)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AdaptiveSampling\\NUTS_compare\\targets.py:161\u001b[0m, in \u001b[0;36mSemiGaussianTarget.zeroOrder\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mzeroOrder\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    160\u001b[0m     temp_vector \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatmul(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minverse, x\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean)\n\u001b[1;32m--> 161\u001b[0m     norm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtemp_vector\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m norm\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def Gaussian_sampler(seed, dimension, numIter, numSamples, initialStep):\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    Target = target_func(dimension, if_simple = True)\n",
    "    \n",
    "    # To Do: double check this formula\n",
    "    hatC = (1+Target.alpha)*(1/Target.alpha)**(Target.alpha/(1+Target.alpha))*(1/np.pi)**(2/(1+Target.alpha))*2**((-1-2*Target.alpha)/(1+Target.alpha))\n",
    "    min_step_size = hatC/(120*np.log(6/0.01)/np.log(2)*Target.L_alpha*np.sqrt(Target.dimension))\n",
    "    print(f\"min_step_size={min_step_size}\")\n",
    "        \n",
    "    Xsamples_adaptive ,step_sizes = proximal_sampler(initialStep, numSamples, numIter, f = Target, fixed = False)\n",
    "    W2_distances = estimate_W2_Gaussian(Xsamples_adaptive,Target.mean, np.identity(dimension)) # the true cov is I_d\n",
    "\n",
    "    \n",
    "    return W2_distances, step_sizes\n",
    "\n",
    "num_iters = 21\n",
    "trails = 10\n",
    "overall_results = np.zeros([trails,5,num_iters-1])\n",
    "overall_sizes = np.zeros([trails,5,num_iters-1])\n",
    "\n",
    "\n",
    "for index_trail in range(trails):\n",
    "    sizes = np.zeros([5,num_iters])\n",
    "    for one_dimen in [2,4,8,16,32]:\n",
    "        W2_distances, step_sizes = Gaussian_sampler(index_trail,one_dimen,num_iters,50,0.1)\n",
    "        overall_results[index_trail,int(np.log2(one_dimen)-1),:] =  W2_distances[1:]\n",
    "        overall_sizes[index_trail, int(np.log2(one_dimen)-1),:] = np.mean(step_sizes[:,1:],axis = 0)\n",
    "\n",
    "    W2_mean = np.mean(overall_results,axis = 0)\n",
    "    w2_std = np.std(overall_results,axis = 0)\n",
    "    plt.figure(figsize = (5,6))\n",
    "    for dimen_index in range(overall_results.shape[1]):\n",
    "        y = W2_mean[dimen_index,:]\n",
    "        error = 2* w2_std[dimen_index,:]\n",
    "        one_dimen = 2**(dimen_index+1)\n",
    "        plt.errorbar(list(range(1, num_iters)), y, yerr=error, fmt='o', ecolor='r', \n",
    "                     capsize=5, capthick=2, elinewidth=2, label=f'd = {one_dimen}')\n",
    "\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Estiamted W2 distance')\n",
    "    ax = plt.gca() \n",
    "    ax.xaxis.set_major_locator(MultipleLocator(4))  \n",
    "    plt.legend()\n",
    "    plt.savefig('W2_dimension.pdf')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    size_mean = np.mean(overall_sizes,axis = 0)\n",
    "    size_std = np.std(overall_sizes,axis = 0)\n",
    "    plt.figure(figsize = (5,6))\n",
    "    for dimen_index in range(overall_sizes.shape[1]):\n",
    "        y = size_mean[dimen_index,:]\n",
    "        error = 2* size_std[dimen_index,:]\n",
    "        one_dimen = 2**(dimen_index+1)\n",
    "        plt.errorbar(list(range(1, num_iters)), y, yerr=error, fmt='o', ecolor='r', \n",
    "                     capsize=5, capthick=2, elinewidth=2, label=f'd = {one_dimen}')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Average step size')\n",
    "    ax = plt.gca() \n",
    "    ax.xaxis.set_major_locator(MultipleLocator(4))  \n",
    "    plt.legend()\n",
    "    plt.savefig('step_dimension.pdf')\n",
    "    plt.close()\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
